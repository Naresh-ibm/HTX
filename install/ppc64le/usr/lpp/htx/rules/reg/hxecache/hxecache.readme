README for hxecache exerciser
================================================================================
Last update:

Table of contents:
================================================================================
1)  Goal
2)  Salient Features
3)  Hardware supported & HW test scope
4)  Supported OS
5)  General info
6)  Prerequisites
7)  Brief Description
8)  Sample Rule Stanza and Explanation
9)  Exerciser specific Log files
10) Understanding htxstats
11) Throughput numbers
12) Common config errors
13) Miscompare analysis
14) Limitations
15) Known Issues


================================================================================

1) Goal:
--------
The goal of hxecache testcase is stress system cpu d-caches & related hardware mechanisms,
by means of the following:
1. A targeted cache rollover (L2 and/or L3) 
2. Creating cache bounces
3. Disrupting/irritating data streams of hardware prefetch engines.

2) Salient Features:
--------------------
1. Targetted L2/L3 rollover supported .
2. Creation of cache bounces supported .
3. Prefetch irritator testcase supported. ( To run as a standalone prefetch irritator, to disrupt
   hardware prefetch streams generated by other exercisers )
4. Upto 4 separate algorithms supported for prefetch irritator.
5. Individual control of each of the prefetch algorithms supported.
6. Exclusive memory used for prefetch threads.
7. Option to exclude a particular core in a chip from executing is supported.

3)Hardware supported & HW test scope:
-------------------------------------
1. Targetted cache Rollover supported for Power7 and later only.
2. Creation of cache bounces supported for Power6 and later.
3. Prefetch irritator algorithm supported for Power6 and later.
4. Stride-n, Partial & Transient prefetch support for Power7 and later only.

4) Supported OS:
----------------
AIX: y
Linux: y
BML: y

5) General info:
----------------
HTX hxecache runs as a user application on top of the OS (AIX,BML,Linux).
In case of miscompare, the exerciser traps to kdb. Each instance of hxecache 
covers 8 processor cores.
(Except when run with rulefile parameter gang_size=1 for the equaliser where it 
runs on 1 logical cpu and effectively targets just 1 core)

Quickstart:
hxecache is a part of mdt.bu (AIX) and mdt.all(BML,Linux). Therefore a quickstart of 
htx with the default mdt file will start the hxecache exerciser too.

6) Prerequisites:
-----------------
- Min h/w : Power6 and later

- s/w config :  Requisite amount of hugepages must be available.
      	        In a normal htx enviornment, the htx setup scripts do the
		job of reserving these pages.

7) Description:
-----------------

Theory of Cache Access Pattern for Maximum Traffic In/Out -

Size of testcase memory to use is dictated by the size of the cache you are targeting.
To ensure that you are able to fill and to roll, or cause every line to be replaced in
the cache, you must use a contiguous block that is a minimum of twice the size of the cache.  

The order in which this memory is accessed is controlled by a minimum of 2 nested loops.  The outer
loop increments the address by the size of a cache line.  The inner loop increments the address
by the size of a set.  Set size is determined by dividing the cache size in bytes by the associativity.
Performing accesses in this manner means that at most, n accesses will be performed before a line
has to be replaced in the cache, where n is equal to the associativity of the cache (16 for the case of
P6 L3). If sequential accesses are used, y accesses may be performed at most before lines are replaced,
where y is equal to the cache size divided by the cache line size (256K for the case of P6 L3).  

set_size = cache_size / cache_asc;
number_lines_in_set = set_size / line size;

addr = testcase memory start;

for (i=0;i<number_lines_in_set;i++,addr+=line_size) {
       for (j=0;j<(cache_asc*2);j++, addr+=set_zize) {
              // perform access at addr (could be a load or store to a ptr=addr)
       }
}


Following is a diagram representation of sets view of physically contiguous memory set:


	--------> Inner For Loop jumps by cache set size
	|
	|
	|
	V
	 Outer For Loop jumps by cache line size


								  Memory Set
			(asc - 1)th set
			----------------			----------------  0 byte
			|		|<---- Set		|		 |
		1	|		|			|16 M page	 |
		---------------	|			|		 |
		|		|	|			|----------------|
0th set	|		|				|		 |
         ---------------	|			|16 M page  |
0 byte 	cache line	|				|		 |		 
	   ---------------	<------	  	|----------------|
			|		Cache View		|		 |
			|					|16 M page	 |
			|					|		 |
			|					|----------------|
			|					|		 |
			|					|16 M page	 |
			|					|		 |
							 	----------------  2*cache_size - 1
	----------------	
(set_size -1)	

Explanation of Testcases supported -

a. CACHE_BOUNCE :

The example above allows for the memory to be accessed in one particular order - increasing from
the start of the testcase memory towards the end, where every testcase will touch the same sets,
classes, and bytes in exactly the same order every time. It allows to target specific set also.

This is accomplished by making the following types of modifications:

1. changing the access of the address from using pointers in a precompiled way to calling a different function  
   depending on how the different types of loads and stores are supported
   (lbz, lhz, lwz, ld). 
2. On SMP box, program creates as many threads (pthreads) as mentioned in rulefile and all of them do
   write/read/compare operations.
3. Every thread operates onto its own strip in 128 byte cache line as mentioned below.

	----------------------------------------------------
	thread 0 | thread 1 | 		-----	   thread n |	
	----------------------------------------------------
	
	This is how 8 byte pattern is used for various lengths of load/stores :
	
	0x0102030405060708
	  ** For byte load/store
	  **** For short load/store
	  ******** For int load/store
	  **************** For long load/store

This access pattern, where different threads bound to different cpus access the memory that maps one physical 
instance of cache, causes bouncing of the cache line to occur across the various physical caches of the cpus.

b. CACHE_ROLLOVER :

Another testcase provided is the cache rollover testcase.There are 2 cases here.

With the prefetch irritator turned on, The access patterns of the threads on the memory that maps the caches 
is slightly different:


			:										:
			:										:			
			:										:
	----------------------------------------------------                        ----------------------------------------------------
	thread 0........				   |			    thread 1........				       |
	----------------------------------------------------                        ----------------------------------------------------
			:										:
			:										:
			:										:
			V										V

The memory segment allocated for a gang is divided into several parts, each mapping a physical instance of cache present within
the span of that gang. Therefore within a gang, we have smaller sub groups of threads, whereby each group acts on the the 
memory that maps the L2/L3 cache of the core those threads are bound to. This way each sub group rolls over the cache for its own 
core.This achieves a rollover of all the caches present for the span of the gang.

With prefetch on, in each sub group, there is only one thread to operate on the cache and the rest (depending on smt value) are the 
prefetch threads. Therefore the access patterns are as shown above.

However, when the prefetch irritator is turned off, and each core is configured at smt > 1, Then the memory access patterns are:

     	 	       		:
	----------------------------------------------------
	thread 0 |					   |	
	----------------------------------------------------
	----------------------------------------------------
	thread 1 |					   |	
	----------------------------------------------------
	----------------------------------------------------
	thread 2 |					   |	
	----------------------------------------------------
	----------------------------------------------------
	thread 3 |					   |	
	----------------------------------------------------
	----------------------------------------------------
	thread 0 |					   |	
	----------------------------------------------------
				:
				:
				V

In other words , all the threads of a core are put to work to roll over the cache of that core. 
Therefore, within a gang, each sub group,will act on the memory area that maps to the cache of that core.


SYNC SUPPORT
-----------------
For both the above test cases, a synchronization mechanism among threads is implemented to make it more effective.
We make use of three sync points, used in the beginning, middle and end of W/R/C operation. This technique ensures 
that all the threads sync up in the beginning to start executing W/R/C operation simultaneously. After completion 
of write operation, all the threads re-sync again before proceeding to R/C operation. Once all the threads are done 
reading and comparing, they move on to next iteration simultaneously.

The sync mechanism is optional and can be turned off from the rule file.

SYNC MECHANISM
--------------

pthread_cond_wait and pthread_cond_broadcast APIs from pthread library is used to create synchronisation between threads.
The mechanism used is as follows. 
A separate function called synchronize_threads is called. In the function a static counter ( for the rule stanza ) is kept 
to keep track of the count of the threads which have called this function. The counter is incremented everytime the function is called.
The count value (after incrementing) is mod-d by the number of cache threads running.

count = count % num_cache_threads;

In case the result is not 0 ( or the exit_flag is not set ), then the thread performs a wait on a condition variable.
In case the result is 0 ( or external exit flag has been set because of shutdown initiation), then the threads (if any) waiting 
on the condition variable are broadcasted to proceed, and they are not blocked any more.

In this way, as long as the counter does not count to a value equal to number of current running cache threads, all threads wait.
The moment all threads have called this function (essentially counting upto number of cache threads running), all threads are awoken
and start executing in unison.

c. PREFETCH_ONLY :

This is another testcase that is now offered. The intention is to have hxecache run stand alone with only the 
prefetch irritator component enabled so that it functions to disrupt the prefetch streams initiated by other 
exercisers. This testcase is only valid when the prefetch irritator is enabled.

The Prefetch Irritator -

Prefetch Irritator is a component of hxecache exerciser and can be turned off/on from rule file. Main goal of prefetch 
irritator function of hxecache is to kick off software initiated prefetch engines in a random fashion on a different memory 
set which is used by hxecache.

Prefetch engines are initialised to kick off prefetching alongside cachestress program. Various versions of dcbt and dcbtst 
are used to perform the above by randomizing all the possible fields.

Prefetch irritator threads work on their exclusive memory and do not share memory with the hxecache threads.This allows for 
more effective disruption of prefetch streams initiated by hxecache threads OR by threads of other exercisers.

The number of prefetch threads created depends on the number of logical cpus present on the system. 

Normally for ST 16 streams can be allocated but in SMT case  each thread can have a maximum of 8 streams [8*2 maximum number].
If more streams need to allocated then the existing streams are replaced. 

Prefetch Irritator thread obtains the starting address and the specific prefetch algorithm to run. Each prefetch thread acts 
on its own exclusive memory area. To allow for a conservative memory model, we have 2 prefetch threads sharing one 16M page.
The number of pages on which prefetch irritator will operate on is calculated assuming 16M pages are being used.

Each of these threads would first initialise the prefetch streams using various forms of dcbt and dcbtst to kick off prefetch engine.
 
All the inputs that are fed to preftch irritator are seed based and that includes :

a) Offset address  of the page from where the irritator starts prefetching.
b) Offset within cache line  that is consumed to keep prefetch running.
c) Direction of prefetching i.e either forward or backward.
d) Depth of prefecting.

For every load, L1 data are prefetched and every store,  L2 data is prefetched. Two lines and a maximum of 24 lines ahead 
can be prefetched for L1 and L2 respectively . 
 
In order to keep the prefetch engine running data has to be consumed in sequential manner. Prefetch threads run in parallel 
with cache stressing threads of hxecache. As irritator would keep fetching data at random addresses this it would try disrupting 
the execution of cache stress which is basic idea of the prefetch irritator.

Variants of Prefetch irritator for P7 ---

1. Prefetch N stride :   This is a stream variant of dcbt instruction which  specifies which data units 
   to access  that are not adjacent in an address space but are separated by a fixed distance i.e. stride manner.
   This data stream variant specifies the following which are randomized using a seed for various runs  : 
·	Word Granularity access stride 
·	Unit size 
   Streams are consumed by executing load instructions from the EA prefetched but in strided manner. 

2. Transient dcbt : This is an enhancement to the dcbt instruction such that with 
   TH=0b10000, it provides a hint that usage of a soon-to-be-referenced datum is 
   transient. This hint may be used to trigger a prefetch of data into the processor's cache 
   hierarchy in a way that minimizes displacement of other data whose usage has not been
   identified as transient Using the mentioned basic structure of prefetch , 
   engines are kicked off  but the only difference being the data would be transient  .
   Streams are consumed by executing load instructions from the EA prefetched , one word /cache line.    

3. Partial dcbt : This is an enhancement to the dcbt instruction such that with TH=0b11000 it provides a hint that 
   a soon-to-be-referenced datum has limited spatial locality. This hint might be used to trigger a  prefetch of data
   into the processor's cache hierarchy using a partial cache block transaction on the memory bus, thus reducing 
   memory bus bandwidth usage . In this test case one chooses the size in a random fashion and kicks off
   prefetch engines for a given EA. Streams are consumed by executing load instructions from the same EA
   prefetched , one word /(2+24+1)cache lines , as data shouldn't be in L3 prior . 

Each of these variants OR any combination of the above can be enabled/disabled  via the rule file.

* Note:
Only the default prefetch irritator is supported for P6. The above mentioned specialised algorithms are only
valid if set on P7 and later.
There is no separate global flag to turn off the prefetch irritator. A combination of "OFF" for all prefetch algorithms
constitutes the prefetch irritator being disabled.

SETUP
-----
This is a 64-bit binary , its main aim is to achieve cache roll-over . 
One would find one instance of hxecache program running [ e.g /dev/cache0 ] running on 8 logical cpus [SMT is OFF] 
						or
					on 16 cpus [SMT=2 is ON] .
					        or
					on 32 cpus [SMT=4 is ON]
							
Each instance of hxecache , spawns 'n' hxecache threads which runs on 'n' logical processors if SMT is OFF . Prefetch 
Irritator testcase wouldn't be executed when SMT is off irrespective of rule file value .

Each instance of hxecache , spawns 'n/2' hxecache threads and 'n/2' prefetch irritator threads which run on alternate
on total of 'n'logical cpus in case of SMT=2 is ON .

Each instance of hxecache , spawns 1:3 hxecache to prefetch threads which run on each logical cpu with SMT=4 is ON .
SMT = 4 ON , hxecache thread would run on logical cpu 0 . Each variant of prefetch irritator would run on other three
logical cpus . N_stride , partial and transient are the three variants of prefetch irritator.  


8) Sample Rule Stanza with explanation:
---------------------------------------

rule_id			L3Roll_Prefetch_1
target_cache	 	L3
compare			1
bound			0
target_set 		-1
data_width		2
crash_on_misc		1
num_oper		100
prefetch_irritator	1
prefetch_nstride	1
prefetch_partial	1
prefetch_transient	0
seed			0
testcase_type   	CACHE_ROLL_WITH_PREF
thread_sync		no
gang_size		8
exclude_cores         	1,2 


Explanations of rule file keywords:

rule_id 	- Indicates rule stanza number. We support upto 10 rule stanzas in the rule files for hxecache.
		  The rule string has to end with an underscore and a number. (e.g. rule_1)
target_cache	- Indicates the cache under test i.e L2 cache or L3 cache.
compare		- Indicates if a compare should be done after a write to cache memory , 1 => YES 0 => NO
bound		- Applicable only for uni threaded. (Can be ignored )
target_set  	- Refers to any specific target set to stress. 16 way L3 cache will take values from 0-15.
	      	  Default is -1, where all sets are targeted.

data_width    	- Width of data to be written to the cache memory. 
	          i.e 0 => byte, 1 => short, 2 => int, 3 => long int, 4 => random 
crash_on_misc   - Whether to crash to kernel debugger incase of miscompare.
		  0 => NO 1 => YES
    		  0 - No, 1 - Yes. Following will be the contents of registers
		  while dropping to kernel debugger:
		  r3 - 0xBEEFDEAD
		  r4 - EA of miscompare location
		  r5 - pointer to 8 byte pattern
		  r6 - address of memory_set structure
		  r7 - address of system_information structure
		  r8 - Thread no [ sequence of creation ] 
		  r9 - Pointer to thread_context structure for the thread.
		  r10 - Pointer to current index of rule_info structure.

num_oper 	- Number of times L2 or L3 cache would roll over.
	  	  0 => Infinitely  
	  	  Suitable values for P6 are < 50 to avoid unusually long execution times.

Each prefetch algorithm can be enabled/disabled using the below where 0 => OFF 1=> ON.
prefetch_irritator	0
prefetch_nstride	1
prefetch_partial	1
prefetch_transient	1


seed 		- To run the test with a particular seed . Used for recreate in case of a failure. 0 - Normal run.
testcase_type  	- Indicates which testcase is to run. 
	       	  CACHE_BOUNCE_WITH_PREF 	- This causes cache bouncing along with Prefetch threads. 1 cache thread and 3 prefetch threads per core.
		  CACHE_BOUNCE_ONLY	   	- Cache Bounce with 1 cache thread per core.		        	
		  CACHE_ROLL_WITH_PREFETCH	- This causes cache to rollover. 1 cache thread and 3 prefetch threads per core.
		  CACHE_ROLL_ONLY		- Cache Rollover with only cache threads and no Prefetch. SMT cache threads per core.
		  PREFETCH_ONLY			- Software Prefetching Testcase.

gang_size 	- Indicates the number of physical instances of cache that will be covered.
	    	  Default 8.
	    	  Could also be set to 1 ONLY when running under the Equaliser framework.
	    	  
thread_sync	- It is used to configure whether synchronisation among threads is desired or not.
		  yes - means Sync is desired
		  no  - means sync is not desired
		  By default sync is disabled.
		  
exclude_cores	- To disable any particular core, mention the core number in this field.
 		  If multiple cores are to be excluded, separate them with comma(s).
 		  This field is optional and may not be included in the rule file if disabling cores is not desired.



9) Exerciser specific Log files:
--------------------------------
1. /tmp/hxecachex.runlog (where x is the instance number) - contains run time log from exerciser. By default logging is very minimum and dumps only rulefile paramters.
2. /tmp/hxecache_miscompare.ab.cde.xxxxxx - It is generated ONLY in case of a miscompare. It contains the hexdump of the 16M page where a thread has found miscompare.

10) Understanding htxstats:
---------------------------

Hxecache statistics appear as follows and are primarily a figure of bytes read/written per 
second (and per instance ofcourse):

cache0:
  cycles                              =                  0
  # good reads                        =               4000
  # bytes read                        =         2097152000
  # good writes                       =               4000
  # total instructions                =                  0
  # bytes written                     =         2097152000
  # good others                       =                  0
  # bad others                        =                  0
  # bad reads                         =                  0
  # bad writes                        =                  0
  # data transfer rate(bytes_wrtn/s)  =         4744688.00
  # data transfer rate(bytes_read/s)  =         4744688.00
  # instruction throughput(MIPS)      =           0.000000


11) Throughput numbers:
-----------------------

12) Common config errors:
-------------------------

If testcase_type is set to CACHE_TEST_OFF without any of the prefetch algorithms being enabled, the
testcase would be ineffective.

If num_oper is set too high for any exerciser. ( This number varies across systems and configurations ), the
execution time may be unusually high, and may report the exerciser as HUNG.

The optimal range for P6 would be between 10 and 50.
The optimal range for P7 would be between 100 and 1000.


13) Miscompare analysis:
------------------------

ERROR MESSAGES 
--------------
*************
In case of miscompare, following details are dumped in HTX error log and message log:

Exact prints from /tmp/htxerr should be like following :

/dev/cache        Feb  6 05:22:20 2007 err=00000000 sev=1 hxecache

 RB: TID: 0 miscompare !! EA = 0x5000002b data = 0 pattern = ff

KDB registers will contain :
r3 - 0xBEEFDEAD
r4 - EA of miscompare location
r5 - pointer to 8 byte pattern
r6 - address of memory_set structure
r7 - address of system_information structure
r8 - Thread no [ sequence of creation ] 
r9 - Pointer to thread_context structure for the thread.
r10 - Pointer to current index of rule_info structure.

For debugging hxecache miscompare on KDB prompt, compare data pointed to by r4 and r5.
Amount of data that needs to be compared is in thrad_context structure.

After debug is done, please continue (and do not reboot) from KDB prompt. It will generate a miscompare file, which will have hexdump of the 16M 
page where the thread detected a miscompare.
The name of the miscompare file will be /tmp/hxecache_miscompare.ab.cde.xxxxxx
where,
ab     = instance number of cache exerciser
cde    = index of the miscomparing thread
xxxxxx = seed for the thread.

*************
If you see following error in /tmp/htxerr, it indicates that hxecache could not find
required amount of physically contiguous memory and hence it could not run. In such
scenario, please reboot the system and try once again.

/dev/cache        Mar 24 11:55:39 2007 err=ffffffff sev=1 hxecache

 Could not get physically contig mem....Exiting....
*************

14) Limitations:
----------------
Current limitations:

a. Hxecache does not support Halting and restarting the run of the exerciser [which is done through option 2 from supervisor 

b. Cannot perform a cache rollover for Power 6, due the the huge memory requirements.
   No plans to support the same in the future.
   
c. This exerciser is not supported on shared LPARs. It will only run (/dev/cachex devices will be created) only on a dedicated LPAR.

15) Known Issues:
-----------------
List Open issues.




